version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: argos-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      # Persist models between restarts
      - ollama-data:/root/.ollama
    environment:
      # Temporary: Remove optimizations to debug hang issue
      # - OLLAMA_NUM_PARALLEL=1           # May be causing deadlock
      # - OLLAMA_MAX_LOADED_MODELS=1      # Only load one model at a time
      # - OLLAMA_CONTEXT_LENGTH=2048      # May be incompatible with 1b model
      - OLLAMA_KEEP_ALIVE=5m            # Increase from 1m to 5m
      - OLLAMA_MAX_LOADED_MODELS=1      # Keep this one
    networks:
      - argos-network
    deploy:
      resources:
        limits:
          # Reduced to 2G: llama3.2:1b uses ~1.3GB on disk, ~1.8GB loaded
          # Only 1b model allowed on RPi 5 8GB (3b model deleted - caused OOM crashes)
          memory: 2G
        reservations:
          memory: 1G

volumes:
  ollama-data:
    driver: local

networks:
  argos-network:
    driver: bridge
